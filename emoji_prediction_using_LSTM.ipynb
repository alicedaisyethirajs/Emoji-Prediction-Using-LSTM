{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z69m5xRfWZTG",
        "outputId": "4fe615c3-53ad-4f68-e18a-8e38d34bdaa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ],
      "source": [
        "%pip install emoji"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "emoji is a library that helps handle emojis in text — useful for decoding, encoding, or filtering emoji content."
      ],
      "metadata": {
        "id": "IF9fpCfWnLXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import numpy as np: Imports NumPy, a numerical computing library used for arrays, matrices, and mathematical functions.\n",
        "\n",
        "import pandas as pd: Imports pandas, which is used for working with tabular data like CSVs or DataFrames.\n",
        "\n",
        "import emoji: Brings in the emoji package you just installed.\n",
        "\n",
        "Why this is needed:\n",
        "\n",
        "numpy helps in handling numerical operations during model processing.\n",
        "\n",
        "pandas is likely used for loading and exploring the emoji dataset.\n",
        "\n",
        "emoji helps manage emoji characters — either for cleaning, identifying, or encoding them.\n",
        "\n"
      ],
      "metadata": {
        "id": "mpVaSRHZnPcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji"
      ],
      "metadata": {
        "id": "hwBqcm9VoQyB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential: A linear stack of layers from Keras; used to build the neural network step by step.\n",
        "\n",
        "Dense: A fully connected layer, where every input neuron is connected to every output neuron.\n",
        "\n",
        "LSTM: Long Short-Term Memory, a special kind of RNN for sequence prediction problems (great for text).\n",
        "\n",
        "SimpleRNN: A basic Recurrent Neural Network layer (not as powerful as LSTM, but simpler).\n",
        "\n",
        "Embedding: Turns integer-encoded words into dense vectors of fixed size — useful for inputting text into models.\n",
        "\n",
        "Then from tensorflow.keras.preprocessing:\n",
        "\n",
        "Tokenizer: Converts text into a sequence of integers.\n",
        "\n",
        "pad_sequences: Ensures all input sequences are of the same length by padding them (important for batching).\n",
        "\n",
        "to_categorical: Converts class labels (like 0,1,2) into one-hot vectors — useful for classification tasks.\n",
        "\n",
        "Why this is needed:\n",
        "This cell sets up all the tools needed for:\n",
        "\n",
        "Preprocessing text,\n",
        "\n",
        "Building a neural network that understands sequences,\n",
        "\n",
        "Predicting emoji classes from text.\n",
        "\n"
      ],
      "metadata": {
        "id": "DE-WSNx5nWbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,SimpleRNN,Embedding\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "YqHAK4kYohRb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"emoji_data.csv\",header = None)"
      ],
      "metadata": {
        "id": "qsgMFmGyo8Fk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uw-kaSUYppU9",
        "outputId": "d5241b36-18f5-416a-b613-da14f3961734"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             0   1\n",
              "0  French macaroon is so tasty   4\n",
              "1             work is horrible   3\n",
              "2                   I am upset  3 \n",
              "3               throw the ball  1 \n",
              "4                    Good joke   2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c767639-3a0a-49c3-8b2e-ac1e0315dc33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French macaroon is so tasty</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>work is horrible</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am upset</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>throw the ball</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Good joke</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c767639-3a0a-49c3-8b2e-ac1e0315dc33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c767639-3a0a-49c3-8b2e-ac1e0315dc33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c767639-3a0a-49c3-8b2e-ac1e0315dc33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3f106770-8a9a-442f-af51-4aa0bcceebad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f106770-8a9a-442f-af51-4aa0bcceebad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3f106770-8a9a-442f-af51-4aa0bcceebad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 183,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 181,\n        \"samples\": [\n          \"where is the ball\",\n          \"he is a good friend\",\n          \"go away\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"1\",\n          \"4\",\n          \"0 \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_dict = {\n",
        "    0:\"red_heart:\",\n",
        "    1:\":baseball:\",\n",
        "    2:\":grinning_face_with_big_eyes:\",\n",
        "    3:\":disappointed_face:\",\n",
        "    4:\":fork_and_knife:\"\n",
        "}\n",
        "\n",
        "\n",
        "def label_to_emoji(label):\n",
        "  return emoji.emojize(emoji_dict[label])"
      ],
      "metadata": {
        "id": "15W4IX5jqt8C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "emoji_dict: A dictionary mapping numeric class labels (0 to 4) to corresponding emoji names in colon format.\n",
        "\n",
        "These names come from the Unicode CLDR short name for emojis.\n",
        "\n",
        "Example: :red_heart: gets converted to ❤️.\n",
        "\n",
        "label_to_emoji(label):\n",
        "\n",
        "A helper function that takes a label like 0 and returns the actual emoji using emoji.emojize().\n",
        "\n",
        "emoji.emojize(':red_heart:') will return ❤️.\n",
        "\n",
        "Why this is needed:\n",
        "\n",
        "Models work with numeric labels (e.g., 0, 1, 2), but we want to show the actual emoji in results.\n",
        "\n",
        "This function makes it easy to translate predicted labels back to human-readable emojis.\n",
        "\n"
      ],
      "metadata": {
        "id": "9D87lipsnfzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[0].values\n",
        "Y=data[1].values"
      ],
      "metadata": {
        "id": "YrHDdylrrC4f"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sI5NCuErHfE",
        "outputId": "7d35cbc2-5bfd-4e6f-f969-232cf96aedbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['French macaroon is so tasty', 'work is horrible', 'I am upset',\n",
              "       'throw the ball', 'Good joke',\n",
              "       'what is your favorite baseball game', 'I cooked meat',\n",
              "       'stop messing around', 'I want chinese food',\n",
              "       'Let us go play baseball', 'you are failing this exercise',\n",
              "       'yesterday we lost again', 'Good job', 'ha ha ha it was so funny',\n",
              "       'I will have a cheese cake', 'Why are you feeling bad',\n",
              "       'I want to joke', 'I never said yes for this',\n",
              "       'the party is cancelled', 'where is the ball', 'I am frustrated',\n",
              "       'ha ha ha lol', 'she said yes', 'he got a raise',\n",
              "       'family is all I have', 'he can pitch really well',\n",
              "       'I love to the stars and back', 'do you like pizza ',\n",
              "       'You totally deserve this prize', 'I miss you so much',\n",
              "       'I like your jacket ', 'she got me a present',\n",
              "       'will you be my valentine', 'you failed the midterm',\n",
              "       'Who is down for a restaurant', 'valentine day is near',\n",
              "       'Great so awesome', 'do you have a ball', 'he can not do anything',\n",
              "       'he likes baseball', 'We had such a lovely dinner tonight',\n",
              "       'vegetables are healthy', 'he is a good friend',\n",
              "       'never talk to me again', 'i miss her', 'food is life',\n",
              "       'I am having fun', 'So bad that you cannot come with us',\n",
              "       'do you want to join me for dinner ', 'I like to smile',\n",
              "       'he did an amazing job', 'Stop shouting at me',\n",
              "       'I love taking breaks',\n",
              "       'You are incredibly intelligent and talented',\n",
              "       'I am proud of your achievements', 'So sad you are not coming',\n",
              "       'funny', 'Stop saying bullshit',\n",
              "       'Bravo for the announcement it got a lot of traction',\n",
              "       'This specialization is great',\n",
              "       'I was waiting for her for two hours ',\n",
              "       'she takes forever to get ready ',\n",
              "       'My grandmother is the love of my life', 'I will celebrate soon',\n",
              "       'my code is working but the grader gave me zero',\n",
              "       'She is the cutest person I have ever seen', 'he is laughing',\n",
              "       'I adore my dogs', 'I love you mum', 'great job',\n",
              "       'How dare you ask that', 'this guy was such a joke',\n",
              "       'I love indian food', 'Are you down for baseball this afternoon',\n",
              "       'this is bad', 'Your stupidity has no limit', 'I love my dad',\n",
              "       'Do you want to give me a hug', 'this girl was mean',\n",
              "       'I am excited', 'i miss him', 'What is wrong with you',\n",
              "       'they are so kind and friendly',\n",
              "       'I am so impressed by your dedication to this project',\n",
              "       'we made it', 'I am ordering food', 'Sounds like a fun plan ha ha',\n",
              "       'I am so happy for you', 'Miss you so much', 'I love you',\n",
              "       'this joke is killing me haha',\n",
              "       'You are not qualified for this position', 'miss you my dear',\n",
              "       'I want to eat', 'I am so excited to see you after so long',\n",
              "       'he is the best player', 'What a fun moment',\n",
              "       'my algorithm performs poorly', 'Stop shouting at me',\n",
              "       'her smile is so charming', 'It is the worst day in my life',\n",
              "       'he is handsome', 'no one likes him', 'she is attractive',\n",
              "       'It was funny lol', 'he is so cute', 'you did well on you exam',\n",
              "       'I think I will end up alone', 'Lets have food together',\n",
              "       'too bad that you were not here', 'I want to go play',\n",
              "       'you are a loser', 'I am starving', 'you suck', 'Congratulations',\n",
              "       'you could not solve it', 'I lost my wallet',\n",
              "       'she did not answer my text ', 'That catcher sucks ',\n",
              "       'See you at the restaurant', 'I boiled rice', 'I said yes',\n",
              "       'candy is life ', 'the game just finished',\n",
              "       'The first base man got the ball',\n",
              "       'congratulations on your acceptance',\n",
              "       'The assignment is too long ', 'lol',\n",
              "       'I got humiliated by my sister', 'I want to eat',\n",
              "       'the lectures are great though ', 'you did not do your homework',\n",
              "       'The baby is adorable', 'Bravo', 'I missed you',\n",
              "       'I am looking for a date', 'where is the food', 'you are awful',\n",
              "       'any suggestions for dinner', 'she is happy',\n",
              "       'I am always working', 'This is so funny', 'you got a down grade',\n",
              "       'I want to have sushi for dinner', 'she smiles a lot',\n",
              "       'The chicago cubs won again', 'I got approved', 'cookies are good',\n",
              "       'I hate him', 'I am going to the stadium',\n",
              "       'I am very disappointed', 'I am proud of you forever',\n",
              "       'This girl is messing with me', 'Congrats on the new job',\n",
              "       'enjoy your break', 'go away', 'I worked during my birthday',\n",
              "       'Congratulation fon have a baby', 'I am hungry',\n",
              "       'She is my dearest love', 'she is so cute', 'I love dogs',\n",
              "       'I did not have breakfast ', 'my dog just had a few puppies',\n",
              "       'I like you a lot', 'he had to make a home run',\n",
              "       'I am at the baseball game', 'are you serious ha ha',\n",
              "       'I like to laugh', 'Stop making this joke ha ha ha',\n",
              "       'you two are cute', 'This stupid grader is not working',\n",
              "       'What you did was awesome', 'My life is so boring',\n",
              "       'he did not answer', 'lets exercise', 'you brighten my day',\n",
              "       'I will go dance', 'lets brunch some day', 'dance with me',\n",
              "       'she is a bully', 'she plays baseball',\n",
              "       'I like it when people smile'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMiomQzLrJNG",
        "outputId": "b330dbdf-bddd-4637-cd92-f47576d93e22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['4', '3', '3 ', '1 ', '2', '1', '4', '3', '4', '1', '3', '3 ', '2',\n",
              "       '2', '4', '3', '2', '3 ', '3 ', '1', '3 ', '2', '2', '2', '0', '1',\n",
              "       '0', '4 ', '2', '0v2', '2', '0', '0', '3 ', '4', '0', '2', '1',\n",
              "       '3', '1', '0', '4', '0 ', '3', '0 ', '4', '2', '3 ', '4', '2 ',\n",
              "       '2', '3', '0', '2', '2', '3 ', '2', '3', '2', '2', '3 ', '3', '0 ',\n",
              "       '2', '3', '0', '2', '0', '0 ', '2', '3', '2', '4', '1', '3', '3',\n",
              "       '0', '0', '3', '2', '0', '3', '0', '2', '2', '4', '2', '2', '0',\n",
              "       '0', '2', '3', '0', '4', '2', '1', '2', '3', '3', '2', '3', '0',\n",
              "       '3', '0', '2', '0', '2', '3', '4', '3', '1', '3', '4', '3', '2',\n",
              "       '3', '3', '3', '1', '4', '4', '2', '2', '1', '1', '2', '3', '2',\n",
              "       '3', '4', '2', '3', '0', '2', '0', '0', '4', '3', '4', '2', '3',\n",
              "       '2', '3', '4', '2', '1', '2', '4', '3', '1', '3', '2', '3', '2',\n",
              "       '2', '3', '3', '2', '4', '0', '0', '0', '3', '0', '0', '1', '1',\n",
              "       '2', '2', '2', '0', '3', '2', '3', '3', '1', '2', '2', '4', '2',\n",
              "       '3', '1', '2'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data[0]: Refers to the first column of the dataset — this column contains the input sentences (text).\n",
        "\n",
        "data[1]: Refers to the second column — this contains the emoji labels (as numbers 0–4).\n",
        "\n",
        ".values: Converts the pandas Series into a NumPy array for easier processing."
      ],
      "metadata": {
        "id": "kS3I1Wr6nn-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding"
      ],
      "metadata": {
        "id": "qkL6Qv3erMwj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UUcz80mrK3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlNIDNf0rSnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "432d4f87",
        "outputId": "f74ac7a5-350b-4f72-f18b-c4d81efdb818"
      },
      "source": [
        "!wget --no-check-certificate http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-21 12:45:13--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-06-21 12:45:13--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-06-21 12:45:14--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "WARNING: cannot verify downloads.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA 2,O=Internet2,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 39s  \n",
            "\n",
            "2025-06-21 12:47:53 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file = open('glove.6B.100d.txt', 'r', encoding = 'utf8')\n",
        "content = file.readlines()\n",
        "file.close()\n",
        "# content"
      ],
      "metadata": {
        "id": "6ohZ89nsrYRV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe (Global Vectors for Word Representation) provides pre-trained word vectors that can be used to convert text into numerical form. These are much richer than simple one-hot or integer encoding."
      ],
      "metadata": {
        "id": "5wqzH2KMn4Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = {}\n",
        "\n",
        "\n",
        "for line in content:\n",
        "  line = line.split()\n",
        "  embeddings[line[0]] = np.array(line[1:], dtype = float)"
      ],
      "metadata": {
        "id": "bNtXMU8Brb4i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are loading the GloVe embeddings into memory, so that in the next steps, you can:\n",
        "\n",
        "Convert them into a dictionary,\n",
        "\n",
        "Look up embeddings for words in your training data,\n",
        "\n",
        "Use them in your model's embedding layer."
      ],
      "metadata": {
        "id": "Ed70c8NEn93f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  get_maxlen(data):\n",
        "  maxlen = 0\n",
        "  for sent in data:\n",
        "    maxlen = max(maxlen,len(sent))\n",
        "  return maxlen\n",
        "\n",
        "# Tokenize the input data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "Xtokens = tokenizer.texts_to_sequences(X)\n",
        "word2index = tokenizer.word_index\n",
        "\n",
        "\n",
        "maxlen = get_maxlen(Xtokens)\n",
        "print(maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWl6GFE6h0IZ",
        "outputId": "2981cbb1-bd68-46dc-c960-fce262aea889"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're preparing your text data for deep learning by:\n",
        "\n",
        "Converting text into sequences of integers.\n",
        "\n",
        "Figuring out how much padding is needed.\n",
        "\n",
        "Getting the vocabulary-to-index mapping for embedding lookup."
      ],
      "metadata": {
        "id": "ui7IbiuloLbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = pad_sequences(Xtokens,maxlen = maxlen, padding = 'post', truncating = 'post')"
      ],
      "metadata": {
        "id": "DV0EZtSYi20i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the index of the row with '0v2' in the original data\n",
        "invalid_index = data[data[1] == '0v2'].index[0]\n",
        "\n",
        "# Remove the row from both X and Y\n",
        "X = np.delete(X, invalid_index)\n",
        "Y = np.delete(Y, invalid_index)\n",
        "\n",
        "# Convert Y to integer type\n",
        "Y = Y.astype(int)\n",
        "\n",
        "Y_train = to_categorical(Y)"
      ],
      "metadata": {
        "id": "KMOYfiybjnwY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block:\n",
        "\n",
        "Makes your input sequences uniform.\n",
        "\n",
        "Fixes a bad label.\n",
        "\n",
        "Converts labels into one-hot format so that they’re ready for training in a classification model."
      ],
      "metadata": {
        "id": "oqyAM_cJoQfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "e3JuINZNj5IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 100\n",
        "embedding_matrix = np.zeros((len(word2index)+1, embed_size))\n",
        "\n",
        "\n",
        "\n",
        "for word, i in word2index.items():\n",
        "  embed_vector = embeddings[word]\n",
        "  embedding_matrix[i] = embed_vector"
      ],
      "metadata": {
        "id": "s64gSCGHjvS2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This matrix will later be passed into a keras.layers.Embedding(...) layer with weights=[embedding_matrix], so your model starts with rich semantic understanding from pre-trained GloVe vectors — instead of learning everything from scratch."
      ],
      "metadata": {
        "id": "LFtF8tigokJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOL89c7OkR-v",
        "outputId": "c35a4d0e-6e66-4fc6-8c53-07bcea1f23ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
              "         0.      ],\n",
              "       [-0.046539,  0.61966 ,  0.56647 , ..., -0.37616 , -0.032502,\n",
              "         0.8062  ],\n",
              "       [-0.49886 ,  0.76602 ,  0.89751 , ..., -0.41179 ,  0.40539 ,\n",
              "         0.78504 ],\n",
              "       ...,\n",
              "       [-0.46263 ,  0.069864,  0.69095 , ..., -0.29174 ,  0.32041 ,\n",
              "         0.21202 ],\n",
              "       [ 0.073242,  0.11134 ,  0.62281 , ...,  0.53417 , -0.1646  ,\n",
              "        -0.27516 ],\n",
              "       [ 0.29019 ,  0.80497 ,  0.31187 , ..., -0.33603 ,  0.45998 ,\n",
              "        -0.11278 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential ([\n",
        "    Embedding(input_dim = len(word2index)+1,\n",
        "                              output_dim = embed_size,\n",
        "                              input_length = maxlen,\n",
        "                              weights = [embedding_matrix],\n",
        "                              trainable = False\n",
        "    ),\n",
        "\n",
        "    LSTM(units = 16, return_sequences = True),\n",
        "    LSTM(units = 4),\n",
        "    Dense(5, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer ='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "0ZmJ0SAekZwq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converts sentences into word vectors using pre-trained GloVe embeddings.\n",
        "\n",
        "Passes them through 2 LSTM layers to capture sequential context.\n",
        "\n",
        "Outputs probabilities across 5 emoji categories using a softmax classifier."
      ],
      "metadata": {
        "id": "_NVIIcSnowrf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQfE8drUlOgu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sFgCjes-lgSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55e926da",
        "outputId": "22b1e17c-0c79-416f-8e56-46c0afff67ad"
      },
      "source": [
        "# Re-tokenize and re-pad X after removing the invalid row\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "Xtokens = tokenizer.texts_to_sequences(X)\n",
        "word2index = tokenizer.word_index\n",
        "\n",
        "maxlen = get_maxlen(Xtokens)\n",
        "Xtrain = pad_sequences(Xtokens,maxlen = maxlen, padding = 'post', truncating = 'post')\n",
        "\n",
        "print(f\"Shape of Xtrain: {Xtrain.shape}\")\n",
        "print(f\"Shape of Y_train: {Y_train.shape}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Xtrain: (182, 10)\n",
            "Shape of Y_train: (182, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "resetting everything related to tokenization and sequence formatting after deleting a problematic row — ensuring the model won't crash and that the data is consistent."
      ],
      "metadata": {
        "id": "oHdPrrqGpMf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain,Y_train,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBhFu6dMlt4C",
        "outputId": "114e027b-1424-4362-b3f2-800ed0c57386"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.2943 - loss: 1.5861\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3285 - loss: 1.5514\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2595 - loss: 1.5548\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3101 - loss: 1.5136\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2962 - loss: 1.5068\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3500 - loss: 1.4837\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3358 - loss: 1.4727\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3477 - loss: 1.4528\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3414 - loss: 1.4357\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3902 - loss: 1.3874\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4079 - loss: 1.3607\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4212 - loss: 1.3412\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5164 - loss: 1.2949\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5044 - loss: 1.2724\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4780 - loss: 1.2616\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5314 - loss: 1.2048\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5657 - loss: 1.1925\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5381 - loss: 1.1865\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6415 - loss: 1.1018\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6368 - loss: 1.0707\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6445 - loss: 1.1366\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6152 - loss: 1.0265\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6891 - loss: 1.0353\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6619 - loss: 1.0079\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7321 - loss: 0.9308\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7536 - loss: 0.9113\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7597 - loss: 0.8745\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8094 - loss: 0.8611\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7636 - loss: 0.8680\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8119 - loss: 0.8299\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7971 - loss: 0.7963\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8158 - loss: 0.7999\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8687 - loss: 0.7528\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8428 - loss: 0.7184 \n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8975 - loss: 0.7189\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8865 - loss: 0.6924\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9238 - loss: 0.6349\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9123 - loss: 0.6429\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9128 - loss: 0.6176\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9185 - loss: 0.6131\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9162 - loss: 0.5776\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9253 - loss: 0.5561\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9380 - loss: 0.5519 \n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9495 - loss: 0.5346\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9274 - loss: 0.5354\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9274 - loss: 0.5403\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9454 - loss: 0.4923\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9365 - loss: 0.4933\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9221 - loss: 0.5091\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9286 - loss: 0.4837\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9291 - loss: 0.4721\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9250 - loss: 0.4839\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9187 - loss: 0.4829\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9266 - loss: 0.4727\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9441 - loss: 0.4508\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9315 - loss: 0.4514\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9277 - loss: 0.4444\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9212 - loss: 0.4390\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9407 - loss: 0.4098\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9164 - loss: 0.4538\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9463 - loss: 0.3964\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9400 - loss: 0.4241\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9195 - loss: 0.4191\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9358 - loss: 0.3945\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9190 - loss: 0.4422\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9261 - loss: 0.4096\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9237 - loss: 0.4039\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9300 - loss: 0.3959\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9232 - loss: 0.4039\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9427 - loss: 0.3682\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9277 - loss: 0.3837\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9324 - loss: 0.3687\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9302 - loss: 0.3909\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9289 - loss: 0.3698\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9492 - loss: 0.3382\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9523 - loss: 0.3413\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9499 - loss: 0.3293\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9399 - loss: 0.3494\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9263 - loss: 0.3880\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9347 - loss: 0.3527\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9396 - loss: 0.3701\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9379 - loss: 0.3548\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9284 - loss: 0.3718\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9347 - loss: 0.3545\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9338 - loss: 0.3624\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9382 - loss: 0.3508\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9609 - loss: 0.2991\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9504 - loss: 0.3045\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9219 - loss: 0.3674\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9497 - loss: 0.3157\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9503 - loss: 0.3055\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9411 - loss: 0.3334\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9298 - loss: 0.3554\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9254 - loss: 0.3502\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9529 - loss: 0.2966\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9470 - loss: 0.3117\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9359 - loss: 0.3268\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9635 - loss: 0.2690\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9407 - loss: 0.3139\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9298 - loss: 0.3313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7abf2706e010>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = ['Im good','i feel cold ','lets catch up for coffee']\n",
        "\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test)\n",
        "Xtest = pad_sequences(test_seq, maxlen = maxlen, padding = 'post', truncating = 'post')\n",
        "\n",
        "\n",
        "y_pred = model.predict(Xtest)\n",
        "y_pred = np.argmax(y_pred,axis =1)\n",
        "\n",
        "\n",
        "for i in range(len(test)):\n",
        "  print(test[i],label_to_emoji(y_pred[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGnmWoNflwlU",
        "outputId": "9d5113ad-c162-4915-fc88-ec613824b6e5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "Im good 😃\n",
            "i feel cold  😞\n",
            "lets catch up for coffee 🍴\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block shows a full inference pipeline:\n",
        "\n",
        "Clean and encode new input.\n",
        "\n",
        "Predict emoji classes using the trained model.\n",
        "\n",
        "Convert numeric class predictions to actual emojis.\n",
        "\n",
        "Display results."
      ],
      "metadata": {
        "id": "JZfZ995MpYUw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4MYzyilmcc_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
